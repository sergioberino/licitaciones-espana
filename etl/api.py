import argparse
import os
import subprocess
import sys
from datetime import datetime
from pathlib import Path

import psycopg2
from fastapi import FastAPI
from fastapi.responses import JSONResponse
from pydantic import BaseModel

from etl.cli import cmd_scheduler_register, cmd_scheduler_run, cmd_scheduler_stop, _comprobar_base_datos
from etl.config import get_database_url, get_db_schema
from etl.ingest_l0 import CONJUNTOS_REGISTRY
from etl.scheduler import get_current_running_run, get_next_run_at, list_tasks_with_last_run, recover_stale_runs


def _ingest_log_path() -> Path:
    return Path(os.environ.get("LICITACIONES_TMP_DIR", "/tmp")) / "ingest.log"


class IngestRunBody(BaseModel):
    """Body for POST /ingest/run. Same options as CLI ingest command."""

    conjunto: str
    subconjunto: str | None = None
    anos: str | None = None
    solo_descargar: bool = False
    solo_procesar: bool = False


class SchedulerRegisterBody(BaseModel):
    """Body for POST /scheduler/register. Optional list of conjuntos; if empty, register all."""

    conjuntos: list[str] = []


class SchedulerRunBody(BaseModel):
    """Body for POST /scheduler/run. Optional conjunto/subconjunto for single task; detach to run loop in background."""

    conjunto: str | None = None
    subconjunto: str | None = None
    detach: bool = False

app = FastAPI(title="ETL API", version="1.0")


@app.on_event("startup")
def _startup_recover_stale_runs():
    """Auto-heal stale 'running' scheduler records left by dead containers."""
    db_url = get_database_url()
    if not db_url:
        return
    try:
        with psycopg2.connect(db_url) as conn:
            conn.autocommit = False
            count = recover_stale_runs(conn)
            conn.commit()
            if count:
                print(f"[startup] Recovered {count} stale scheduler run(s).")
    except Exception as e:
        print(f"[startup] Could not recover stale runs: {e}")


def _serialize_row(row: dict) -> dict:
    """Convert a row dict to JSON-serializable form (datetime -> ISO string)."""
    out = dict(row)
    for key in ("started_at", "finished_at", "last_started_at", "last_finished_at", "next_run_at", "created_at"):
        val = out.get(key)
        if isinstance(val, datetime):
            out[key] = val.isoformat()
    return out


@app.get("/health")
def health():
    return {"status": "ok"}


@app.get(
    "/ingest/conjuntos",
    summary="List ingest conjuntos and subconjuntos",
    description="Returns the same conjunto/subconjunto catalog as the CLI (ingest --subconjuntos). Used by the frontend to populate the Ingestar form.",
)
def ingest_conjuntos():
    """List available conjuntos and their subconjuntos for ingest."""
    conjuntos = [
        {
            "id": cid,
            "subconjuntos": list(reg.get("subconjuntos", [])),
        }
        for cid, reg in sorted(CONJUNTOS_REGISTRY.items())
        if cid != "test"
    ]
    return {"conjuntos": conjuntos}


@app.post(
    "/ingest/run",
    summary="Run ingest for a conjunto/subconjunto (non-blocking)",
    description="Validates inputs then spawns the CLI ingest command as a background process. "
    "Returns immediately with 200. The subprocess registers its own scheduler run "
    "and updates it on completion. Poll GET /ingest/current-run for status and "
    "GET /ingest/log for live subprocess output.",
)
def ingest_run(body: IngestRunBody):
    """Spawn a background ingest process for the given conjunto/subconjunto."""
    conjunto = (body.conjunto or "").strip().lower()
    if not conjunto:
        return JSONResponse(
            status_code=422,
            content={"detail": "conjunto is required"},
        )
    if conjunto not in CONJUNTOS_REGISTRY or conjunto == "test":
        return JSONResponse(
            status_code=422,
            content={
                "detail": f"Conjunto no reconocido: {conjunto}. Admitidos: {', '.join(sorted(c for c in CONJUNTOS_REGISTRY if c != 'test'))}.",
            },
        )
    reg = CONJUNTOS_REGISTRY[conjunto]
    subconjuntos = list(reg.get("subconjuntos", []))
    subconjunto = (body.subconjunto or "").strip() or None
    if subconjunto is None and len(subconjuntos) == 1:
        subconjunto = subconjuntos[0]
    if subconjunto is None and len(subconjuntos) > 1:
        return JSONResponse(
            status_code=422,
            content={"detail": f"Para '{conjunto}' indique subconjunto. VÃ¡lidos: {', '.join(subconjuntos)}."},
        )
    if subconjunto and subconjunto not in subconjuntos:
        return JSONResponse(
            status_code=422,
            content={"detail": f"Subconjunto no reconocido para {conjunto}: {subconjunto}."},
        )
    anos = (body.anos or "").strip() or ""
    if reg.get("requires_anos") and not anos:
        return JSONResponse(
            status_code=422,
            content={"detail": "Obligatorio indicar anos X-Y para este conjunto (ej. 2023-2023)."},
        )

    cmd = [sys.executable, "-m", "etl.cli", "ingest", conjunto]
    if subconjunto:
        cmd.append(subconjunto)
    if anos:
        cmd.extend(["--anos", anos])
    if body.solo_descargar:
        cmd.append("--solo-descargar")
    if body.solo_procesar:
        cmd.append("--solo-procesar")

    log_path = _ingest_log_path()
    log_path.parent.mkdir(parents=True, exist_ok=True)

    try:
        log_file = open(log_path, "w", encoding="utf-8")
        kwargs: dict = {"stdout": log_file, "stderr": subprocess.STDOUT}
        if os.name != "nt":
            kwargs["start_new_session"] = True
        p = subprocess.Popen(cmd, **kwargs)
    except Exception as e:
        return JSONResponse(
            status_code=500,
            content={"ok": False, "message": f"No se pudo iniciar el ingest: {e}"},
        )

    label = f"{conjunto}/{subconjunto}" if subconjunto else conjunto
    return {
        "ok": True,
        "message": f"Ingest de {label} iniciado en segundo plano (PID: {p.pid}). "
        f"Consulte el panel para seguir el progreso.",
    }


@app.post(
    "/scheduler/register",
    summary="Register scheduler tasks",
    description="Populate scheduler.tasks from CONJUNTOS_REGISTRY. Optional body: { \"conjuntos\": [\"nacional\", ...] }. If conjuntos empty or omitted, register all. Returns 200 with summary.",
)
def scheduler_register(body: SchedulerRegisterBody | None = None):
    """Register scheduler tasks for given conjuntos or all."""
    conjuntos = (body and body.conjuntos) or []
    args = argparse.Namespace(conjuntos=conjuntos)
    try:
        rc = cmd_scheduler_register(args)
    except Exception as e:
        return JSONResponse(status_code=500, content={"ok": False, "message": str(e)})
    if rc != 0:
        return JSONResponse(status_code=500, content={"ok": False, "message": "Register failed (see server logs)"})
    return {"ok": True, "message": "Tasks registered"}


@app.post(
    "/scheduler/run",
    summary="Run scheduler or single task",
    description="If conjunto (and subconjunto if needed) given: run that task once (blocking, 200). If detach=true: start full scheduler loop in background (202). Reuses CLI logic.",
)
def scheduler_run(body: SchedulerRunBody | None = None):
    """Run a single task or start the scheduler loop in background."""
    body = body or SchedulerRunBody()
    conjunto = (body.conjunto or "").strip() or None
    subconjunto = (body.subconjunto or "").strip() or None
    if not body.detach and not conjunto:
        return JSONResponse(
            status_code=422,
            content={"detail": "Indique conjunto y subconjunto para una tarea, o detach=true para el bucle en background."},
        )
    if conjunto and subconjunto is None and conjunto in CONJUNTOS_REGISTRY:
        subs = list(CONJUNTOS_REGISTRY[conjunto].get("subconjuntos", ()))
        if len(subs) == 1:
            subconjunto = subs[0]
        elif len(subs) > 1:
            return JSONResponse(
                status_code=422,
                content={"detail": f"El conjunto '{conjunto}' tiene varios subconjuntos. Indique uno: {', '.join(subs)}."},
            )
    if conjunto and not subconjunto and not body.detach:
        return JSONResponse(
            status_code=422,
            content={"detail": "Indique subconjunto para esta tarea."},
        )
    args = argparse.Namespace(
        conjunto=conjunto,
        subconjunto=subconjunto,
        run_all=body.detach,
        tick_seconds=60,
        detach=body.detach,
    )
    try:
        rc = cmd_scheduler_run(args)
    except Exception as e:
        return JSONResponse(status_code=500, content={"ok": False, "message": str(e)})
    if rc != 0:
        return JSONResponse(status_code=500, content={"ok": False, "message": "Run failed (see server logs)"})
    if body.detach:
        return JSONResponse(status_code=202, content={"ok": True, "message": "Scheduler started in background"})
    return {"ok": True, "message": "Task completed"}


@app.post(
    "/scheduler/stop",
    summary="Stop scheduler process",
    description="Send SIGTERM to the scheduler process (same as CLI 'scheduler stop'). Returns 200.",
)
def scheduler_stop():
    """Stop the scheduler process."""
    args = argparse.Namespace()
    try:
        rc = cmd_scheduler_stop(args)
    except Exception as e:
        return JSONResponse(status_code=500, content={"ok": False, "message": str(e)})
    if rc != 0:
        return JSONResponse(status_code=500, content={"ok": False, "message": "Stop failed (scheduler not running or invalid PID)"})
    return {"ok": True, "message": "Scheduler stop requested"}


@app.post(
    "/scheduler/recover",
    summary="Recover stale scheduler runs",
    description="Detect orphaned 'running' records (dead PID or timed-out) and mark them as failed. Safe to call at any time.",
)
def scheduler_recover():
    """Manually trigger stale-run recovery."""
    db_url = get_database_url()
    if db_url is None:
        return JSONResponse(status_code=503, content={"ok": False, "message": "Database not configured"})
    try:
        with psycopg2.connect(db_url) as conn:
            conn.autocommit = False
            count = recover_stale_runs(conn)
            conn.commit()
    except psycopg2.Error as e:
        return JSONResponse(status_code=500, content={"ok": False, "message": str(e)})
    return {"ok": True, "recovered": count}


@app.get("/status")
def status():
    ok, msg = _comprobar_base_datos()
    if ok:
        return {"status": "ok", "database": "connected"}
    return JSONResponse(
        status_code=503,
        content={"status": "error", "database": "unavailable"},
    )


@app.get("/scheduler/status")
def scheduler_status():
    url = get_database_url()
    if url is None:
        return JSONResponse(
            status_code=503,
            content={"tasks": []},
        )
    try:
        with psycopg2.connect(url) as conn:
            rows = list_tasks_with_last_run(conn)
    except psycopg2.Error:
        return JSONResponse(
            status_code=503,
            content={"tasks": []},
        )
    list_of_dicts = []
    for row in rows:
        r = dict(row)
        if r.get("last_status") == "running":
            r["next_run_at"] = None
        else:
            next_at = get_next_run_at(
                r.get("schedule_expr") or "Trimestral",
                r.get("last_finished_at"),
            )
            r["next_run_at"] = next_at
        list_of_dicts.append(_serialize_row(r))
    return {"tasks": list_of_dicts}


@app.get(
    "/ingest/log",
    summary="Tail the ingest subprocess log",
    description="Returns the last N lines of the ingest log file written by the background subprocess. "
    "Poll this while an ingest is running to show live progress.",
)
def ingest_log(lines: int = 80):
    """Read the tail of the ingest subprocess log."""
    log_path = _ingest_log_path()
    if not log_path.exists():
        return {"lines": [], "exists": False, "total_lines": 0}
    try:
        text = log_path.read_text(encoding="utf-8", errors="replace")
    except OSError:
        return {"lines": [], "exists": True, "total_lines": 0}
    all_lines = text.splitlines()
    tail = all_lines[-lines:] if len(all_lines) > lines else all_lines
    return {"lines": tail, "exists": True, "total_lines": len(all_lines)}


@app.get("/ingest/current-run")
def ingest_current_run():
    """Return the currently running ingest run (if any)."""
    url = get_database_url()
    if url is None:
        return JSONResponse(status_code=503, content={"running": False, "run": None})
    try:
        with psycopg2.connect(url) as conn:
            run = get_current_running_run(conn)
    except psycopg2.Error:
        return JSONResponse(status_code=503, content={"running": False, "run": None})
    if not run:
        return {"running": False, "run": None}
    return {"running": True, "run": _serialize_row(run)}


@app.get("/db-info")
def db_info():
    url = get_database_url()
    if url is None:
        return JSONResponse(
            status_code=503,
            content={"detail": "database unavailable"},
        )
    db_schema = get_db_schema()
    schemas = ([db_schema] if db_schema else []) + ["dim", "scheduler"]
    placeholders = ", ".join(["%s"] * len(schemas))
    try:
        with psycopg2.connect(url) as conn:
            with conn.cursor() as cur:
                cur.execute(
                    f"""
                    SELECT nspname AS schema_name,
                           pg_size_pretty(SUM(pg_total_relation_size(c.oid))::bigint) AS size
                    FROM pg_class c
                    JOIN pg_namespace n ON n.oid = c.relnamespace
                    WHERE nspname IN ({placeholders})
                    GROUP BY nspname
                    """,
                    schemas,
                )
                sizes = cur.fetchall()
                cur.execute(
                    f"""
                    SELECT table_schema, table_name
                    FROM information_schema.tables
                    WHERE table_schema IN ({placeholders})
                      AND table_type = 'BASE TABLE'
                    ORDER BY table_schema, table_name
                    """,
                    schemas,
                )
                tables = cur.fetchall()
    except psycopg2.Error:
        return JSONResponse(
            status_code=503,
            content={"detail": "database error"},
        )
    return {
        "schemas": [{"schema_name": r[0], "size": r[1]} for r in sizes],
        "tables": [{"schema": r[0], "name": r[1]} for r in tables],
    }
